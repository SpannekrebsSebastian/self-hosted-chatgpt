# Self-Hosted AI Assistant mit Discord Crawler & RAG

## ğŸ“Œ Beschreibung
Dieses Projekt kombiniert einen **lokalen KI-Assistenten (Ollama)** mit einem **Discord-Crawler**, **GitHub- & Stack Overflow-Scraper** und einer **Retrieval-Augmented Generation (RAG)**, um aktuelle Entwicklerinfos fÃ¼r DevSecOps, Fullstack & KI bereitzustellen.

## ğŸš€ Features
- ğŸ–¥ **Self-Hosted KI** â†’ LÃ¤uft mit Ollama & lokalen LLMs (`mistral`, `mixtral`, `deepseek-coder`)
- ğŸ¤– **Discord-Integration** â†’ Crawlt Nachrichten aus Entwickler-Channels
- ğŸ“ **GitHub & Stack Overflow API** â†’ Holt Issues & Fragen zu relevanten Themen
- ğŸ” **Vektorbasierte Suche mit FAISS** â†’ Speichert & sucht relevante Infos
- ğŸ›  **Automatisches Training mit LoRA/QLoRA** â†’ Falls neue Daten gefunden werden
- ğŸ–¼ **GUI** â†’ Benutzerfreundliche OberflÃ¤che mit `tkinter`

## ğŸ“‚ Installation & Einrichtung
### **1ï¸âƒ£ AbhÃ¤ngigkeiten installieren**
Falls `pip` noch nicht alle Pakete installiert hat, fÃ¼hre folgendes aus:
```sh
pip install discord.py faiss-cpu numpy openai requests tk PyGithub langchain
```
Falls du eine **NVIDIA-GPU** hast, kannst du `faiss-gpu` anstelle von `faiss-cpu` verwenden:
```sh
pip install faiss-gpu
```

### **2ï¸âƒ£ Umgebungsvariablen setzen**
Ersetze die API-Tokens in der `self_hosted_chat.py`:
```python
TOKEN = "DEIN_DISCORD_BOT_TOKEN"
GITHUB_TOKEN = "DEIN_GITHUB_TOKEN"
```
Falls du Channels begrenzen mÃ¶chtest:
```python
CHANNEL_IDS = [123456789012345678]  # Discord Channel-IDs
```

### **3ï¸âƒ£ Starte die Anwendung**
```sh
python self_hosted_chat.py
```
Falls Ollama nicht automatisch startet, kannst du es manuell starten:
```sh
ollama serve
```

## ğŸ“– Nutzung
- **Gib Fragen in die GUI ein** â†’ Das Modell sucht relevante Infos aus Discord/GitHub/Stack Overflow & antwortet
- **Neue Daten in FAISS speichern** â†’ Automatische Speicherung & Abrufbarkeit
- **Discord-Crawler lÃ¤uft automatisch** â†’ Holt & speichert neue Nachrichten

## âš  Fehlerbehebung
### âŒ `ModuleNotFoundError: No module named 'faiss'`
LÃ¶sung:
```sh
pip install faiss-cpu  # oder faiss-gpu bei NVIDIA-GPU
```
Falls es weiterhin nicht funktioniert:
```sh
pip install faiss-cpu --no-cache-dir
```

### âŒ `Ollama Fehler: Port 11434 belegt`
Falls Ollama nicht startet:
```sh
netstat -ano | findstr :11434  # PrÃ¼fe, ob der Port belegt ist
```
Falls Ollama bereits lÃ¤uft:
```sh
ollama serve
```
Falls ein anderer Prozess den Port blockiert:
```sh
taskkill /PID <PID> /F
```

## ğŸ“Œ Weiterentwicklung
- ğŸ›  **Integration von weiteren APIs** â†’ Mehr Datenquellen wie Hacker News oder Reddit
- ğŸ§  **Bessere LLM-Optimierung** â†’ Feintuning der Modelle fÃ¼r spezifische Aufgaben
- ğŸŒ **Web-Frontend** â†’ Moderne Web-OberflÃ¤che statt `tkinter`

---
Made with â¤ï¸ by Sebastian Spannekrebs

